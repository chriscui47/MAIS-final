# -*- coding: utf-8 -*-
"""deliverable2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17-L7Yy4EbZS4PICw3a7HmRqeyxhMGc8S

We will test various models then plot the accuracies. First, we start with Random Forest.

We start by splitting our data into an 80- 20 train testing split. We then scale the data
"""

from sklearn.ensemble import RandomForestClassifier
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score
from sklearn import svm
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
import matplotlib.pyplot as plt
import pandas_profiling as pp
from sklearn.metrics import accuracy_score

from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform
#we might need precision too? 

#to do: make a graph for accuracies usign the different models

df = 'https://raw.githubusercontent.com/chriscui47/MAIS-final/master/heart.csv'
data = pd.read_csv(df)
pp.ProfileReport(data)

#extract the x and y values
X=data.iloc[:,0:12].values
y=data.iloc[:,13].values


#assign values by splitting data
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

#scale our data
sc=StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.transform(X_test)

"""We run a gridsearch on our Randomforest model. Out puts,"""

param_grid = {
    'bootstrap': [True],
    'max_depth': [70,110,150,200,230,280,350,400,430],
    
    'min_samples_leaf': [3, 4, 5],
    'min_samples_split': [8, 10, 12],
    'n_estimators': [100,130,140,150,170,200,220]
}
# Create a based model
rf = RandomForestRegressor()
# Instantiate the grid search model
grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, 
                          cv = 3, n_jobs = -1, verbose = 2)
grid_search.fit(X_train, y_train)
grid_search.best_params_

"""After RF gridsearch, apply the best parameters to the model"""

regresserRF=RandomForestClassifier(bootstrap=True,n_estimators=100,max_depth=350,min_samples_leaf=4,min_samples_split=8)
regresserRF.fit(X_train,y_train)
print(accuracy_score(y_test,regresserRF.predict(X_test)))
#gridsearch? hyperparameter space, you randomly select

"""Now, do gridearch on logistic regression, and apply them to model and print accuracies
---
"""

# Create grid search object
param_grid2 = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],'penalty': ['l1','l2'],'random_state':[0,1]}
clfLR = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid2,n_jobs=-1,verbose=0,cv = 3)
clfLR.fit(X_train,y_train)
print("BEST STUFF IS {}".format(clfLR.best_params_))

clfLRF = LogisticRegression(C=1,penalty='l2',random_state=0)
clfLRF.fit(X_train, y_train)
y_predLRF=clfLRF.predict(X_test)
print("Logistic regression accuracy:",accuracy_score(y_test,y_predLRF))

##BEST STUFF IS {'C': 0.1, 'penalty': 'l2', 'random_state': 0}

"""Try baggging classifier, with a SVC base. Then, try regualr svc with gridsearch.
Bagging has 85.24 accuracy! comapred to 81.9 from regular svc.
"""

from sklearn.svm import SVC
from sklearn.ensemble import BaggingClassifier  
from sklearn.datasets import make_classification
clfBC = BaggingClassifier(base_estimator=SVC(),
                     n_estimators=20, random_state=0).fit(X_train, y_train)
print("Bagging accuracy:",accuracy_score(y_test,clfBC.predict(X_test)))


param_gridSVC = {'C': [0.1, 1, 10,14,16,17,20,22,25,29,33,35, 100, 1000],  
               'gamma': [1, 0.1, 0.01, 0.001, 0.0001],
               'kernel': ['poly','rbf','sigmoid'],
               'degree': [1,2,3,4,5]
                   }  
  
gridSVC = GridSearchCV(SVC(), param_grid=param_gridSVC, refit = True, verbose = 0) 
  
#fitting the model for grid search 
gridSVC.fit(X_train, y_train) 
print(gridSVC.best_params_) 

svc=SVC(C=0.1,degree=1,gamma=0.1,kernel='poly')
#parameters: c=0.1, degree =1, gamma =0.1, kernel =poly
svc.fit(X_train,y_train)
svcpred=svc.predict(X_test)
print("svc accuracy",accuracy_score(y_true=y_test,y_pred=svcpred))

"""Bagging classifier has highest accuracy of 85.24!"""